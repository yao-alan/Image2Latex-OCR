{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import preprocessing as pre\n",
    "import dataset as ds\n",
    "import utils\n",
    "from vocab import Vocab, label_to_index, indices_to_latex\n",
    "from model import CRNN, init_weights\n",
    "from IPython.display import clear_output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **GET TRAIN/VAL/TEST SPLIT** #"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data_root = '../data'\n",
    "data_folders = ['IM2LATEX-100K', 'IM2LATEX-100K-HANDWRITTEN']\n",
    "img_folders = ['formula_images', 'images']\n",
    "\n",
    "# imgs stored in data_root/data_folders/img_folders\n",
    "assert len(data_folders) == len(img_folders)\n",
    "\n",
    "# get test/train/val indices\n",
    "# change ftype if different image type used\n",
    "df_list = []\n",
    "for i in range(len(data_folders)):\n",
    "    print(f'{data_root}/{data_folders[i]}')\n",
    "    df = pre.data_to_df(f'{data_root}/{data_folders[i]}', max_entries=None)\n",
    "    df['dataset'] = data_folders[i]\n",
    "    df_list.append(df)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **APPEND LABELS**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "label_folders = ['im2latex_formulas.lst', 'formulas.lst']\n",
    "\n",
    "for i, df in enumerate(df_list):\n",
    "    labels = pre.extract_labels(f'{data_root}/{data_folders[i]}/{label_folders[i]}')\n",
    "    df['label'] = labels.loc[df['index']].values\n",
    "    df['label_token_indices'] = np.nan\n",
    "    # image shape after being processed\n",
    "    df['padded_height'] = np.nan\n",
    "    df['padded_width'] = np.nan"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **MERGE AND SHUFFLE DATAFRAMES** #"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "merge_shuffle_df = pd.concat(df_list).sample(frac=1).reset_index(drop=True).astype('object')\n",
    "merge_shuffle_df.to_csv('../saved/merge_shuffle_df.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## *If loading from saved df* ##"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "merge_shuffle_df = pd.read_csv('../saved/merge_shuffle_df.csv').astype('object')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **TOKENIZE LATEX, CREATE FULL DATAFRAME** #"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "image_sizes = [\n",
    "    (40, 160), (40, 200), (40, 240), (40, 280), (40, 320), \\\n",
    "    (50, 120), (50, 200), (50, 240), (50, 280), (50, 320)\n",
    "]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "merge_shuffle_df, images, vocab = pre.scale_images(\n",
    "    merge_shuffle_df,\n",
    "    maxlen=200,\n",
    "    image_sizes=image_sizes,\n",
    "    reshape_strat='pad'\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "merge_shuffle_df.to_csv('../saved/merge_shuffle_df_processed.csv')\n",
    "image_handler = open('../saved/images', 'wb')\n",
    "pickle.dump(images, image_handler)\n",
    "vocab_handler = open('../saved/vocab', 'wb')\n",
    "pickle.dump(vocab, vocab_handler)\n",
    "image_handler.close()\n",
    "vocab_handler.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## *Load items in if everything is saved* ##"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "merge_shuffle_df = pd.read_csv('../saved/merge_shuffle_df_processed.csv')\n",
    "images = pickle.load(open('../saved/images', 'rb'))\n",
    "vocab = Vocab()\n",
    "vocab = pickle.load(open('../saved/vocab', 'rb'))\n",
    "\n",
    "merge_shuffle_df = merge_shuffle_df.astype('object')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "for idx in merge_shuffle_df.index:\n",
    "    clear_output(wait=True)\n",
    "    print(idx)\n",
    "    merge_shuffle_df.at[idx, 'label'] \\\n",
    "        = [x[1:-1] for x in np.asarray(merge_shuffle_df['label'].iloc[idx][1:-1].split(', '))]\n",
    "    merge_shuffle_df.at[idx, 'label_token_indices'] \\\n",
    "        = np.array(merge_shuffle_df['label_token_indices'].iloc[idx][1:-1].split(), dtype=float)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "102460\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **CREATE DATALOADERS** #"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "train_dataloaders = [\n",
    "    ds.gen_dataloader(\n",
    "        merge_shuffle_df=merge_shuffle_df,\n",
    "        images=images,\n",
    "        split='train',\n",
    "        extra_cond=((merge_shuffle_df['padded_height'] == h) & (merge_shuffle_df['padded_width'] == w)),\n",
    "        batch_size=30, \n",
    "        shuffle=True,\n",
    "        merge_train_validate=True\n",
    "    ) for (h, w) in image_sizes\n",
    "]\n",
    "\n",
    "test_dataloaders = [\n",
    "    ds.gen_dataloader(\n",
    "        merge_shuffle_df=merge_shuffle_df,\n",
    "        images=images,\n",
    "        split='test',\n",
    "        extra_cond=((merge_shuffle_df['padded_height'] == h) & (merge_shuffle_df['padded_width'] == w)),\n",
    "        batch_size=30, \n",
    "        shuffle=True,\n",
    "        merge_train_validate=True\n",
    "    ) for (h, w) in image_sizes\n",
    "]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **CONSTRUCT MODEL** #"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "model = CRNN(vocab, embed_size=32)\n",
    "model.apply(init_weights)\n",
    "model.to('cuda:0')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "CRNN(\n",
       "  (cnn): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): PReLU(num_parameters=1)\n",
       "    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (13): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (14): PReLU(num_parameters=1)\n",
       "    (15): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "  )\n",
       "  (embedding): Embedding(874, 32)\n",
       "  (rnn): GRU(544, 256, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n",
       "  (dense): Linear(in_features=512, out_features=874, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## *If there are trained parameters to load in* ##"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "model.load_state_dict(torch.load('../saved/run4/CRNN_params_epoch_5.pt'))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# dataloaders is a list\n",
    "def train_loop(model, train_dataloaders, vocab, num_epochs, lr=0.1, test_dataloaders=None, main_device='cpu'):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, eps=1e-6)\n",
    "    ce_loss = nn.CrossEntropyLoss(reduction='none')\n",
    "    ctc_loss = nn.CTCLoss(blank=vocab.get_index('<nul>'), reduction='none', zero_infinity=True)\n",
    "    animator = utils.Animator(\n",
    "        measurement_names=['ctc_loss'],\n",
    "        refresh=1\n",
    "    )\n",
    "    metrics = utils.MetricBuffer(['sum_ctc_loss', 'n_tokens'])\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "        n_imgs = 0\n",
    "        for dataloader in train_dataloaders:\n",
    "            for i, (imgs, labels) in enumerate(dataloader):\n",
    "                model.train()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                imgs = torch.tensor(imgs).to(main_device).float()\n",
    "                labels = labels.to(main_device).long()\n",
    "                output = model(imgs, teacher_forcing=False)\n",
    "                # output.shape = (seq_len, batch_size, vocab_size)\n",
    "\n",
    "                # for CTCLoss\n",
    "                log_softmax_probs = F.log_softmax(output, dim=2)\n",
    "                labels = labels[:, 1:log_softmax_probs.shape[0]+1]\n",
    "                # requires shape (seq_len, batch_size, vocab_size)\n",
    "                print(log_softmax_probs.shape, labels.shape, (torch.ones((labels.shape[0])) * labels.shape[1]).shape)\n",
    "                main_loss = ctc_loss(\n",
    "                    log_softmax_probs,\n",
    "                    labels, \n",
    "                    (torch.ones((labels.shape[0])) * labels.shape[1]).int().to(output.device),\n",
    "                    (labels != vocab.get_index('<pad>')).sum(dim=1).int().to(output.device)\n",
    "                )\n",
    "\n",
    "                # for CrossEntropyLoss\n",
    "                second_loss = ce_loss(\n",
    "                    output.permute(1, 2, 0),\n",
    "                    labels\n",
    "                )\n",
    "\n",
    "                main_loss.sum().backward()\n",
    "                nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "                optimizer.step()\n",
    "\n",
    "                metrics.update([('sum_ctc_loss', main_loss.sum().cpu().detach().numpy())])\n",
    "                metrics.update([('n_tokens', (labels != vocab.get_index('<pad>')).sum(dim=[0, 1]).cpu().detach().numpy())])\n",
    "\n",
    "                n_imgs += imgs.shape[0]\n",
    "                # print(n_imgs)\n",
    "                \n",
    "                print(i)\n",
    "                if i % 10 == 0:\n",
    "                    clear_output(wait=True)\n",
    "                    print(f\"n_imgs #{n_imgs}\")\n",
    "                    print(f\"Current loss: {metrics['sum_ctc_loss'] / metrics['n_tokens']}\")\n",
    "                    # try printing from test set\n",
    "                    #for test_imgs, test_labels in gen_dataloader('train', batch_size=2, shuffle=True):\n",
    "                    if test_dataloaders is not None:\n",
    "                        test_loader = test_dataloaders[np.random.randint(0, len(test_dataloaders))]\n",
    "                        for test_imgs, test_labels in test_loader:\n",
    "                            model.eval()\n",
    "                            with torch.no_grad():\n",
    "                                output = model(test_imgs.to(main_device).float())\n",
    "                                print(output)\n",
    "                                seq_list = vocab.indices_to_latex(output, vocab)\n",
    "                                label_list = vocab.indices_to_latex(test_labels.int(), vocab)\n",
    "                                print(len(seq_list))\n",
    "                                for i, seq in enumerate(seq_list):\n",
    "                                    plt.imshow(test_imgs[i, 0])\n",
    "                                    plt.show()\n",
    "                                    print(\"Prediction:\")\n",
    "                                    print(seq)\n",
    "                                    print(\"Real:\")\n",
    "                                    print(label_list[i])\n",
    "                                    print()\n",
    "                                    print()\n",
    "                                break\n",
    "            \n",
    "        animator.append([\n",
    "            ('ctc_loss', metrics['sum_ctc_loss'] / metrics['n_tokens']),\n",
    "        ])\n",
    "\n",
    "        metrics.clear()\n",
    "        torch.save(model.state_dict(), f'../saved/main2/CRNN_params_epoch_{epoch}.pt')\n",
    "            \n",
    "    torch.save(model.state_dict(), f'../saved/main2/CRNN_params_epoch_{num_epochs}.pt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_loop(model, train_dataloaders, vocab, num_epochs=5, lr=3e-4, test_dataloaders=test_dataloaders, main_device='cuda:0')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **EVALUATE MODEL** #"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import nltk"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sum_bleu = 0\n",
    "sum_edit = 0\n",
    "n_examples = 0\n",
    "for test_loader in test_dataloaders:\n",
    "    for test_imgs, test_labels in test_loader:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            output = model(test_imgs.to('cuda:0').float())\n",
    "            seq_list = indices_to_latex(output, vocab)\n",
    "            label_list = indices_to_latex(test_labels.int(), vocab, using_ctc_loss=False)\n",
    "            for i, seq in enumerate(seq_list):\n",
    "                plt.imshow(test_imgs[i, 0])\n",
    "                plt.show()\n",
    "                bleu_score = nltk.translate.bleu_score.sentence_bleu([label_list[i]], seq)\n",
    "                edit_dist = nltk.edit_distance(label_list[i], seq)\n",
    "                sum_bleu += bleu_score\n",
    "                sum_edit += edit_dist\n",
    "                n_examples += 1\n",
    "                print(\"Prediction:\")\n",
    "                print(seq)\n",
    "                print(\"Real:\")\n",
    "                print(label_list[i])\n",
    "                print(\"BLEU:\")\n",
    "                print(bleu_score)\n",
    "                print(\"Edit:\")\n",
    "                print(edit_dist)\n",
    "                print()\n",
    "\n",
    "clear_output(wait=True)\n",
    "print(f\"Avg. BLEU-4: {sum_bleu / n_examples}\")\n",
    "print(f\"Avg. edit distance: {sum_edit / n_examples}\")"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('torch': conda)"
  },
  "interpreter": {
   "hash": "8acd2124e7e448ebeaa0a3c30e7a87e5808e5beecdab6a949234874733ef1250"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}